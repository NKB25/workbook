{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installing BasicLingua"
      ],
      "metadata": {
        "id": "zAiN2U-eHjj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install basiclingua"
      ],
      "metadata": {
        "id": "WERogaRjG5TH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Modules"
      ],
      "metadata": {
        "id": "HNbKUa8qHnON"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "SA_HUhDrG4Ur"
      },
      "outputs": [],
      "source": [
        "from basiclingua import GeminiLingua, OpenAILingua, AnyScaleLingua\n",
        "open_ai_key = \"YOUR_OPENAI_KEY\"\n",
        "anyscale_key = \"ANYSCALE_API_KEY\"\n",
        "gemini_key = \"GEMINI_API_KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "sUrZy8DRG4Us"
      },
      "outputs": [],
      "source": [
        "gemini_model = GeminiLingua(api_key=gemini_key)\n",
        "openai_model = OpenAILingua(api_key=open_ai_key)\n",
        "anyscale_model = AnyScaleLingua(api_key=anyscale_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HHtwkTfG4Us"
      },
      "source": [
        "1. Extract Patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "_Z4KwBDdG4Ut",
        "outputId": "6ac1e3e8-11c5-4348-f4b5-dd06b7c2c544"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Entities: {'phone_numbers': ['555-987-2104'], 'person_names': ['Detective Miller', 'Alex Turner', 'Cipher', 'Silver Fox', 'Blackbird'], 'location_names': ['New Alexandria', 'The Crimson Cafe'], 'time_expressions': ['3pm'], 'aliases': ['Silver Fox', 'Blackbird'], 'usernames': ['ShadowHunter1337'], 'physical_descriptions': ['silver hair', 'piercing blue eyes', 'clad in black']}\n",
            "OpenAI Entities: {'phone_numbers': ['555-987-2104'], 'person_names': ['Detective Miller', 'Alex Turner'], 'location_names': ['New Alexandria', 'The Crimson Cafe'], 'time_expressions': ['3pm'], 'aliases': ['Silver Fox', 'Blackbird'], 'usernames': ['ShadowHunter1337'], 'physical_descriptions': ['woman with silver hair and piercing blue eyes', 'man clad in black']}\n",
            "AnyScale Entities: {'phone_numbers': ['555-987-2104'], 'person_names': ['Miller', 'Alex Turner', 'Cipher'], 'location_names': ['New Alexandria', 'The Crimson Cafe'], 'time_expressions': ['3pm'], 'aliases': ['Silver Fox', 'Blackbird'], 'usernames': ['ShadowHunter1337'], 'physical_descriptions': ['silver hair and piercing blue eyes', 'man clad in black']}\n"
          ]
        }
      ],
      "source": [
        "# User Input containing important information\n",
        "user_input = \"\"\"\n",
        "In the bustling metropolis of New Alexandria, Detective Miller was hot on the trail of a notorious hacker known only as \"Cipher.\" A cryptic message intercepted by the cybercrime unit mentioned a meeting at \"The Crimson Cafe, 3pm, table 7,\" and listed two aliases: \"Silver Fox\" and \"Blackbird.\" Miller knew these were likely the hacker's accomplices. His informant, a nervous young man named Alex Turner, claimed Cipher frequented an online forum under the ShadowHunter1337 and often boasted about their exploits. Turner also provided a burner phone number, 555-987-2104, supposedly used by Cipher to contact their associates. Armed with this information, Miller headed to The Crimson Cafe. He arrived early, taking a seat across from table 7, his eyes scanning the room. At precisely 3pm, two individuals approached the table. One, a woman with silver hair and piercing blue eyes, exuded an air of confidence and cunning. The other, a man clad in black, remained silent and watchful. Miller approached them, flashing his badge. \"Excuse me, I'm Detective Miller. I believe you might have information regarding an individual known as Cipher.\" The woman, her lips curling into a sly smile, replied, \"Cipher? Never heard of them.\"\"\"\n",
        "\n",
        "# Patterns to extract\n",
        "patterns = \"phone_numbers, person_names, location_names, time_expressions, aliases, usernames, physical_descriptions\"\n",
        "\n",
        "# Using OpenAI to extract entities\n",
        "gemini_entities = gemini_model.extract_patterns(user_input, patterns=patterns)\n",
        "openai_entities = openai_model.extract_patterns(user_input, patterns=patterns)\n",
        "anyscale_entities = anyscale_model.extract_patterns(user_input, patterns=patterns)\n",
        "\n",
        "# Displaying the extracted entities\n",
        "print(\"Gemini Entities:\", gemini_entities)\n",
        "print(\"OpenAI Entities:\", openai_entities)\n",
        "print(\"AnyScale Entities:\", anyscale_entities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-FYeGArG4Ut"
      },
      "source": [
        "2. Text Translate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "oXMGoOxWG4Ut",
        "outputId": "b5e1c589-c01a-44e7-909c-44d2bf353cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Translation: Als der Sonnenuntergang den Himmel in Orange- und Rosatönen tauchte, raschelte eine sanfte Brise durch die Blätter und erzeugte eine beruhigende Symphonie, während sich der Duft von frisch gebrühtem Kaffee im gemütlichen Café ausbreitete.\n",
            "OpenAI Translation: Als der Sonnenuntergang den Himmel mit Schattierungen von Orange und Pink bemalte, raschelte eine sanfte Brise die Blätter und erschuf eine beruhigende Symphonie, während der Duft von frisch gebrühtem Kaffee das gemütliche Café erfüllte.\n",
            "AnyScale Translation: Als der Sonnenuntergang den Himmel mit Schattierungen von Orange und Pink malte, fuhr ein sanfter Lufthauch durch die Blätter, eine beruhigende Symphonie erschaffend, während der Duft frisch gebrühten Kaffees das gemütliche Café füllte.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = \"\"\"As the sunset painted the sky with shades of orange and pink, a gentle breeze rustled the leaves, creating a soothing symphony, while the aroma of freshly brewed coffee filled the cozy cafe.\"\"\"\n",
        "\n",
        "# Using all model\n",
        "gemini_translation  = gemini_model.text_translate(user_input, target_lang=\"german\")\n",
        "openai_translation = openai_model.text_translate(user_input, target_lang=\"german\")\n",
        "anyscale_translation = anyscale_model.text_translate(user_input, target_lang=\"german\")\n",
        "\n",
        "print(\"Gemini Translation:\", gemini_translation)\n",
        "print(\"OpenAI Translation:\", openai_translation)\n",
        "print(\"AnyScale Translation:\", anyscale_translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlsrGceVG4Ut"
      },
      "source": [
        "3. Text Replace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "0CB2oQWxG4Uu",
        "outputId": "9a72f73a-ecdd-4076-a7a6-41a88d73e5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Replacement: karachi is a very big city in pakistan but what about mumbai and  fareed?\n",
            "OpenAI Replacement: karachi is a very big city in pakistan but what about mumbai and  fareed?\n",
            "AnyScale Replacement: fareed is a very big city in pakistan but what about fareed and fareed?\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''karachi is a very big city in pakistan but what about mumbai and delhi?'''\n",
        "replacement_rules = '''all city names with fareed'''\n",
        "\n",
        "# Using all model\n",
        "gemini_replacement = gemini_model.text_replace(user_input, replacement_rules)\n",
        "openai_replacement = openai_model.text_replace(user_input, replacement_rules)\n",
        "anyscale_replacement = anyscale_model.text_replace(user_input, replacement_rules)\n",
        "\n",
        "print(\"Gemini Replacement:\", gemini_replacement)\n",
        "print(\"OpenAI Replacement:\", openai_replacement)\n",
        "print(\"AnyScale Replacement:\", anyscale_replacement)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OcZN3c9G4Uu"
      },
      "source": [
        "3. NER Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "HKyK4c2xG4Uu",
        "outputId": "03c59eff-3a18-45e8-ea0e-2ebf62bee459"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini NER: {'Output': [''], 'URL': ['youtube.com'], 'ORG': ['Google']}\n",
            "OpenAI NER: {'URL': ['youtube.com']}\n",
            "AnyScale NER: {'URL': ['youtube.com']}\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''i googled youtube.com'''\n",
        "\n",
        "# Using all model\n",
        "gemini_ner = gemini_model.detect_ner(user_input)\n",
        "openai_ner = openai_model.detect_ner(user_input)\n",
        "anyscale_ner = anyscale_model.detect_ner(user_input)\n",
        "\n",
        "print(\"Gemini NER:\", gemini_ner)\n",
        "print(\"OpenAI NER:\", openai_ner)\n",
        "print(\"AnyScale NER:\", anyscale_ner)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxDnXSKiG4Uu"
      },
      "source": [
        "5. Text Summarization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "nktIvqY2G4Uu",
        "outputId": "5d55a140-baa8-408b-daa2-9ad30858a287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Summary: Fareed and Asad will visit the speaker at 5 pm, bringing a gift. The speaker is preparing food and has decorated their house for their guests' arrival. The speaker is excited about the reunion and looks forward to sharing their company over cake and tea.\n",
            "OpenAI Summary: Fareed and Asad are visiting the speaker's house at 5 pm, bringing a gift. The speaker is excited to see them, has prepared cake and tea, and decorated the house for their arrival. They hope for a long visit to catch up and share conversations.\n",
            "AnyScale Summary: Here is a 3 sentences length summary of the text:\n",
            "\n",
            "The narrator is eagerly awaiting the visit of Fareed and Asad to their home, where they will be treated to cake and tea. The narrator is excited to catch up with their friends and show off their decorated home, hoping they will stay for a while. The visit marks a long-awaited reunion, with the narrator having many topics to discuss with their guests.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''Fareed and asad are coming to my house at 5 pm. They are bringing a gift for me. I am very happy to see them. I am going to make a cake and tea for them. I hope they will like it. I am very excited to meet them. I have not seen them for a long time. I hope they will stay for a long time. I have a lot of things to talk to them about. I hope they will like my house. I have decorated it for them. I hope they will like it.'''\n",
        "\n",
        "summary_length = 3\n",
        "\n",
        "# Using all model\n",
        "gemini_summary = gemini_model.text_summarize(user_input, summary_length=summary_length)\n",
        "openai_summary = openai_model.text_summarize(user_input, summary_length=summary_length)\n",
        "anyscale_summary = anyscale_model.text_summarize(user_input, summary_length=summary_length)\n",
        "\n",
        "print(\"Gemini Summary:\", gemini_summary)\n",
        "print(\"OpenAI Summary:\", openai_summary)\n",
        "print(\"AnyScale Summary:\", anyscale_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBAETLHrG4Uu"
      },
      "source": [
        "6. Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "LLz9TEBeG4Uu",
        "outputId": "e1b2d1d5-c10d-433f-e9a8-e7a6ee82602e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini QNA: Fareed and Asad\n",
            "OpenAI QNA: Fareed and Asad are coming to your house at 5 pm.\n",
            "AnyScale QNA: Fareed and asad\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''Fareed and asad are coming to my house at 5 pm. They are bringing a gift for me. I am very happy to see them. I am going to make a cake and tea for them. I hope they will like it. I am very excited to meet them. I have not seen them for a long time. I hope they will stay for a long time. I have a lot of things to talk to them about. I hope they will like my house. I have decorated it for them. I hope they will like it.'''\n",
        "\n",
        "question = \"Who is coming to my house at 5 pm?\"\n",
        "\n",
        "\n",
        "# Using all model\n",
        "gemini_summary = gemini_model.text_qna(user_input, question=question)\n",
        "openai_summary = openai_model.text_qna(user_input, question=question)\n",
        "anyscale_summary = anyscale_model.text_qna(user_input, question=question)\n",
        "\n",
        "print(\"Gemini QNA:\", gemini_summary)\n",
        "print(\"OpenAI QNA:\", openai_summary)\n",
        "print(\"AnyScale QNA:\", anyscale_summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbmaYWOMG4Uv"
      },
      "source": [
        "7. Intent Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "OaXPjQSZG4Uv",
        "outputId": "35c3148a-869d-43af-d589-a48f94c1f11b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Intent: ['social_visit']\n",
            "OpenAI Intent: ['Excitement', 'Anticipation', 'Hospitality', 'Friendship', 'Reunion']\n",
            "AnyScale Intent: ['HOSTINGVISITORS']\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''Fareed and asad are coming to my house at 5 pm. They are bringing a gift for me. I am very happy to see them. I am going to make a cake and tea for them. I hope they will like it. I am very excited to meet them. I have not seen them for a long time. I hope they will stay for a long time. I have a lot of things to talk to them about. I hope they will like my house. I have decorated it for them. I hope they will like it.'''\n",
        "\n",
        "\n",
        "# Using all model\n",
        "gemini_intent = gemini_model.text_intent(user_input)\n",
        "openai_intent = openai_model.text_intent(user_input)\n",
        "anyscale_intent = anyscale_model.text_intent(user_input)\n",
        "\n",
        "print(\"Gemini Intent:\", gemini_intent)\n",
        "print(\"OpenAI Intent:\", openai_intent)\n",
        "print(\"AnyScale Intent:\", anyscale_intent)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y34PggVsG4Uv"
      },
      "source": [
        "8. Generate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "iikpvM7yG4Uv",
        "outputId": "51314183-0650-4171-9215-c88d067e4833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Embedd: [0.025411854, -0.022284605]\n",
            "OpenAI Embedd: [-0.02060304582118988, 0.021993333473801613]\n",
            "AnyScale Embedd: [-0.0234293881803751, -0.04073122516274452]\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''Fareed'''\n",
        "\n",
        "\n",
        "# Using all model\n",
        "gemini_embedd = gemini_model.text_embedd(user_input)\n",
        "openai_embedd = openai_model.text_embedd(user_input)\n",
        "anyscale_embedd = anyscale_model.text_embedd(user_input)\n",
        "\n",
        "print(\"Gemini Embedd:\", gemini_embedd[:2])\n",
        "print(\"OpenAI Embedd:\", openai_embedd[:2])\n",
        "print(\"AnyScale Embedd:\", anyscale_embedd[:2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAGeCPhlG4Uv"
      },
      "source": [
        "9. Spam detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "GtCZJ-0GG4Uv",
        "outputId": "e0c35c30-7f29-46ef-aeb6-d2c9db2bae5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Spam: {'prediction': 'spam', 'explanation': 'The input text contains typical elements of a spam email, such as a promise of a large sum of money and a request for personal information.'}\n",
            "OpenAI Spam: {'prediction': 'spam', 'explanation': 'The text contains typical spam elements such as promises of winning a large amount of money, requests for personal information like bank details, and a sense of urgency. These are common characteristics of spam messages.'}\n",
            "AnyScale Spam: {'class': 'spam', 'explanation': 'The message is trying to trick the user into providing sensitive information (bank details) with a false claim of winning a large sum of money, which is a common characteristic of spam messages.'}\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''he congratulations you have won a lottery of 1000000 dollars. Please provide your bank details to claim the prize.'''\n",
        "\n",
        "# Using all model\n",
        "gemini_spam = gemini_model.detect_spam(user_input)\n",
        "openai_spam = openai_model.detect_spam(user_input)\n",
        "anyscale_spam = anyscale_model.detect_spam(user_input)\n",
        "\n",
        "print(\"Gemini Spam:\", gemini_spam)\n",
        "print(\"OpenAI Spam:\", openai_spam)\n",
        "print(\"AnyScale Spam:\", anyscale_spam)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3-ohhv0G4Uv"
      },
      "source": [
        "10. Spelling Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Rd8WERlYG4Uv",
        "outputId": "18fcd31b-9e46-490a-c283-59b835e38460"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Spellcheck: we will bring the pizza for u\n",
            "OpenAI Spellcheck: we will bring the pizza for u\n",
            "AnyScale Spellcheck: we will bring the pizza for you\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''we willl brange the pizze for u'''\n",
        "\n",
        "# Using all model\n",
        "gemini_spellcheck = gemini_model.text_spellcheck(user_input)\n",
        "openai_spellcheck = openai_model.text_spellcheck(user_input)\n",
        "anyscale_spellcheck = anyscale_model.text_spellcheck(user_input)\n",
        "\n",
        "print(\"Gemini Spellcheck:\", gemini_spellcheck)\n",
        "print(\"OpenAI Spellcheck:\", openai_spellcheck)\n",
        "print(\"AnyScale Spellcheck:\", anyscale_spellcheck)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSW_WI6NG4Uv"
      },
      "source": [
        "11. Semantic Role Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "pH0FT3twG4Uv",
        "outputId": "053dd85d-2ff5-40f6-a00a-0f5a8b150463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini SRL: {'Predicate': 'jumps', 'Agent': 'lion', 'Theme': 'dog'}\n",
            "OpenAI SRL: {'Predicate': 'jumps', 'Agent': 'fox and lion', 'Theme': 'dog'}\n",
            "AnyScale SRL: {'Predicate': 'jumps', 'Agent': 'fox and lion', 'Theme': 'dog'}\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''The quick brown fox and lion jumps over the lazy dog.'''\n",
        "\n",
        "\n",
        "# Using all model\n",
        "gemini_srl = gemini_model.text_srl(user_input)\n",
        "openai_srl = openai_model.text_srl(user_input)\n",
        "anyscale_srl = anyscale_model.text_srl(user_input)\n",
        "\n",
        "print(\"Gemini SRL:\", gemini_srl)\n",
        "print(\"OpenAI SRL:\", openai_srl)\n",
        "print(\"AnyScale SRL:\", anyscale_srl)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoprTjW4G4Uv"
      },
      "source": [
        "12. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "uNYC0eq7G4Uw",
        "outputId": "adc454a1-10af-4ba0-d91d-bd06476c8d56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Sentiment: {'prediction': 'negative', 'explanation': 'The text expresses negative sentiment by saying \"I don\\'t like this pizza at all.\"'}\n",
            "OpenAI Sentiment: {'prediction': 'negative', 'explanation': 'The text \"I like this pizza at all\" can be interpreted as a negative sentiment because the phrase \"at all\" typically implies a lack of enthusiasm or enjoyment.'}\n",
            "AnyScale Sentiment: {'prediction': 'positive', 'explanation': \"The text expresses a positive sentiment, despite the phrase 'at all' which could indicate a negative tone, the presence of 'I like' dominates the sentiment.\"}\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''I like this pizza at all.'''\n",
        "\n",
        "\n",
        "# Using all model\n",
        "gemini_sentiment = gemini_model.text_sentiment(user_input)\n",
        "openai_sentiment = openai_model.text_sentiment(user_input)\n",
        "anyscale_sentiment = anyscale_model.text_sentiment(user_input)\n",
        "\n",
        "print(\"Gemini Sentiment:\", gemini_sentiment)\n",
        "print(\"OpenAI Sentiment:\", openai_sentiment)\n",
        "print(\"AnyScale Sentiment:\", anyscale_sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpZwW7uBG4Uw"
      },
      "source": [
        "13. Topic Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "9L4PKOx-G4Uw",
        "outputId": "e765cf13-1308-4b15-98fd-dfcb8b4aa2dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Topic: {'topic': 'Personal Life', 'explanation': \"The input text is about the topic of Personal Life. The text is about the person's friends coming over to his house and the person is excited to see them and has made preparations for them.\"}\n",
            "OpenAI Topic: {'topic': 'anticipated visit from friends', 'explanation': 'The text talks about friends coming over, bringing a gift, and the excitement and preparation for their visit.'}\n",
            "AnyScale Topic: {'topic_name': 'Social Gathering', 'explanation': \"The text revolves around the theme of a social gathering, specifically a visit from friends to the author's house, with discussions of preparations, gifts, and anticipation.\"}\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''Fareed and asad are coming to my house at 5 pm. They are bringing a gift for me. I am very happy to see them. I am going to make a cake and tea for them. I hope they will like it. I am very excited to meet them. I have not seen them for a long time. I hope they will stay for a long time. I have a lot of things to talk to them about. I hope they will like my house. I have decorated it for them. I hope they will like it.'''\n",
        "\n",
        "\n",
        "\n",
        "# Using all model\n",
        "gemini_sentiment = gemini_model.text_topic(user_input)\n",
        "openai_sentiment = openai_model.text_topic(user_input)\n",
        "anyscale_sentiment = anyscale_model.text_topic(user_input)\n",
        "\n",
        "print(\"Gemini Topic:\", gemini_sentiment)\n",
        "print(\"OpenAI Topic:\", openai_sentiment)\n",
        "print(\"AnyScale Topic:\", anyscale_sentiment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4jX4YAbG4Uw"
      },
      "source": [
        "14. POS Tagging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "-CDBJW2FG4Uw",
        "outputId": "621ca33b-bb99-4a6f-b559-982081c65d5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini POS: {'tag': ['ordinal'], 'value': ['long']}\n",
            "OpenAI POS: {'noun': ['Fareed', 'Asad', 'house', 'gift', 'cake', 'tea', 'time', 'things'], 'verb': ['coming', 'bringing', 'see', 'going', 'make', 'hope', 'meet', 'stay', 'talk', 'decorated', 'like'], 'adjective': ['happy', 'excited', 'long', 'lot'], 'adverb': ['very'], 'pronoun': ['my', 'them', 'it'], 'preposition': ['to', 'for', 'at', 'of'], 'conjunction': ['and'], 'determiner': ['a'], 'time': ['5 pm']}\n",
            "AnyScale POS: {'noun': ['Fareed', 'asad', 'house', 'gift', 'cake', 'tea', 'time', 'things', 'house'], 'verb': ['are', 'coming', 'bringing', 'am', 'going', 'make', 'hope', 'will', 'like', 'meet', 'have', 'seen', 'stay', 'talk', 'have', 'decorated'], 'adjective': ['happy', 'long', 'excited', 'lot', 'long'], 'adverb': ['very'], 'pronoun': ['they', 'I', 'me', 'them'], 'preposition': ['to', 'at', 'for', 'with', 'of', 'about', 'in', 'for', 'with'], 'conjunction': ['and'], 'determiner': ['the', 'a', 'my'], 'cardinal': [], 'foreign': [], 'number': [], 'date': [], 'time': ['5 pm'], 'ordinal': [], 'money': [], 'percent': [], 'symbol': [], 'punctuation': [], 'emoticon': [], 'hashtag': [], 'email': [], 'url': [], 'mention': [], 'phone': [], 'ip': [], 'cashtag': [], 'entity': []}\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''Fareed and asad are coming to my house at 5 pm. They are bringing a gift for me. I am very happy to see them. I am going to make a cake and tea for them. I hope they will like it. I am very excited to meet them. I have not seen them for a long time. I hope they will stay for a long time. I have a lot of things to talk to them about. I hope they will like my house. I have decorated it for them. I hope they will like it.'''\n",
        "\n",
        "# Using all model\n",
        "gemini_pos = gemini_model.detect_pos(user_input)\n",
        "openai_pos = openai_model.detect_pos(user_input)\n",
        "anyscale_pos = anyscale_model.detect_pos(user_input)\n",
        "\n",
        "print(\"Gemini POS:\", gemini_pos)\n",
        "print(\"OpenAI POS:\", openai_pos)\n",
        "print(\"AnyScale POS:\", anyscale_pos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahhkEH5gG4Uw"
      },
      "source": [
        "15. Text Badness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "7GU7TwgJG4Uw",
        "outputId": "25e6fb78-3018-4d63-9ba0-af8fdde1297c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Badness: {'harassment': True, \"harassment_threatening'\": True, 'hate': False, 'hate_threatening': False, 'self_harm': False, 'self_harm_instructions': False, 'self_harm_intent': False, 'sexual': False, 'violence': True, 'violence_graphic': False, 'self-harm': False, 'hate/threatening': False, 'violence/graphic': False, 'self-harm/intent': False, 'self-harm/instructions': False, 'harassment/threatening': True}\n",
            "OpenAI Badness: {'harassment': False, 'harassment_threatening': False, 'hate': False, 'hate_threatening': False, 'self_harm': False, 'self_harm_instructions': False, 'self_harm_intent': False, 'sexual': False, 'sexual_minors': False, 'violence': False, 'violence_graphic': False, 'self-harm': False, 'sexual/minors': False, 'hate/threatening': False, 'violence/graphic': False, 'self-harm/intent': False, 'self-harm/instructions': False, 'harassment/threatening': False}\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "user_input = '''Fareed ia very bad guy'''\n",
        "\n",
        "# Using all model\n",
        "gemini_badwords = gemini_model.text_badness(user_input)\n",
        "openai_badwords = openai_model.text_badness(user_input)\n",
        "\n",
        "print(\"Gemini Badness:\", gemini_badwords)\n",
        "print(\"OpenAI Badness:\", openai_badwords)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd86E9hhG4Uw"
      },
      "source": [
        "16. Text Emojis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "HUwp07ORG4Uw",
        "outputId": "c302842d-8369-4415-9a9d-9cb44dce99dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Emojis: Fareed ia very bad guy Angry face but still i like him Smiling face\n",
            "OpenAI Emojis: Fareed ia very bad guy text respresentation but still i like him angry face\n",
            "AnyScale Emojis: Fareed ia very bad guy angry face but still i like him smiling face with smiling eyes\n"
          ]
        }
      ],
      "source": [
        "# Example usage with emojis\n",
        "user_input = '''Fareed ia very bad guy 😡 but still i like him 😊'''\n",
        "\n",
        "# Using all model\n",
        "gemini_emoji = gemini_model.text_emojis(user_input)\n",
        "openai_emoji = openai_model.text_emojis(user_input)\n",
        "anyscale_emoji = anyscale_model.text_emojis(user_input)\n",
        "\n",
        "print(\"Gemini Emojis:\", gemini_emoji)\n",
        "print(\"OpenAI Emojis:\", openai_emoji)\n",
        "print(\"AnyScale Emojis:\", anyscale_emoji)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lEmVubYG4Ux"
      },
      "source": [
        "17. Text Idioms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "EgMBSsckG4Ux",
        "outputId": "92baafea-4a60-4bdb-ca1f-d0c3e61b3c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Idioms: ['a bad egg', 'a good apple']\n",
            "OpenAI Idioms: ['bad egg', 'good apple']\n",
            "AnyScale Idioms: ['bad egg', 'good apple']\n"
          ]
        }
      ],
      "source": [
        "# Example usage with idioms\n",
        "user_input = '''Fareed is a bad egg but still i like him because he is a good apple'''\n",
        "\n",
        "# Using all model\n",
        "gemini_idioms = gemini_model.text_idioms(user_input)\n",
        "openai_idioms = openai_model.text_idioms(user_input)\n",
        "anyscale_idioms = anyscale_model.text_idioms(user_input)\n",
        "\n",
        "print(\"Gemini Idioms:\", gemini_idioms)\n",
        "print(\"OpenAI Idioms:\", openai_idioms)\n",
        "print(\"AnyScale Idioms:\", anyscale_idioms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2bCRHdnG4Ux"
      },
      "source": [
        "18. Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "Hn6IcWneG4Ux",
        "outputId": "113103b2-65d3-4ce8-9978-087497a93750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Anomaly: ['detected anomalies', 'bad egg', 'good apple']\n",
            "OpenAI Anomaly: ['bad egg, good apple']\n",
            "AnyScale Anomaly: ['bad egg', 'good apple']\n"
          ]
        }
      ],
      "source": [
        "# Example usage with idioms\n",
        "user_input = '''Fareed is a bad egg but still i like him because he is a good apple'''\n",
        "\n",
        "# Using all model\n",
        "gemini_anomaly = gemini_model.text_anomaly(user_input)\n",
        "openai_anomaly = openai_model.text_anomaly(user_input)\n",
        "anyscale_anomaly = anyscale_model.text_anomaly(user_input)\n",
        "\n",
        "\n",
        "print(\"Gemini Anomaly:\", gemini_anomaly)\n",
        "print(\"OpenAI Anomaly:\", openai_anomaly)\n",
        "print(\"AnyScale Anomaly:\", anyscale_anomaly)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9sOzRgRG4Ux"
      },
      "source": [
        "19. Text Coreference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "5ks_KhRYG4U4",
        "outputId": "30ae3bf8-bf7e-4274-e2af-1b6dff320d46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Coreference: {'me': 'None', 'he': 'amjad'}\n",
            "OpenAI Coreference: {'Pronoun': 'he Referent'}\n",
            "AnyScale Coreference: {'he': 'amjad', 'me': 'speaker'}\n"
          ]
        }
      ],
      "source": [
        "# Example usage with idioms\n",
        "user_input = '''me and amjad are going to the market but he said he will not come'''\n",
        "\n",
        "# Using all model\n",
        "gemini_coref = gemini_model.text_coreference(user_input)\n",
        "openai_coref = openai_model.text_coreference(user_input)\n",
        "anyscale_coref = anyscale_model.text_coreference(user_input)\n",
        "\n",
        "print(\"Gemini Coreference:\", gemini_coref)\n",
        "print(\"OpenAI Coreference:\", openai_coref)\n",
        "print(\"AnyScale Coreference:\", anyscale_coref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_GkBLZ_G4U4"
      },
      "source": [
        "19. Text Coreference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "bBJkT26cG4U4",
        "outputId": "33817fd8-2ee0-4ede-ed8f-f361ae0883c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemini Coreference: {'me': 'None', 'he': 'amjad'}\n",
            "OpenAI Coreference: {'me': 'None', 'amjad': 'None', 'he': 'amjad'}\n",
            "AnyScale Coreference: {'he': 'Amjad', 'me': 'speaker'}\n"
          ]
        }
      ],
      "source": [
        "# Example usage with idioms\n",
        "user_input = '''me and amjad are going to the market but he said he will not come'''\n",
        "\n",
        "# Using all model\n",
        "gemini_coref = gemini_model.text_coreference(user_input)\n",
        "openai_coref = openai_model.text_coreference(user_input)\n",
        "anyscale_coref = anyscale_model.text_coreference(user_input)\n",
        "\n",
        "print(\"Gemini Coreference:\", gemini_coref)\n",
        "print(\"OpenAI Coreference:\", openai_coref)\n",
        "print(\"AnyScale Coreference:\", anyscale_coref)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5TKyr2kG4U4"
      },
      "source": [
        "20. Chat with PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTJr4DneG4U4"
      },
      "outputs": [],
      "source": [
        "# Using all model\n",
        "gemini_pdf = gemini_model.chat_pdf(\"who's cv is this and what's his latest experience?\", \"My_PDF.pdf\")\n",
        "openai_pdf = openai_model.chat_pdf(\"who's cv is this and what's his latest experience?\", \"My_PDF.pdf\")\n",
        "anyscale_pdf = anyscale_model.chat_pdf(\"who's cv is this and what's his latest experience?\", \"My_PDF.pdf\")\n",
        "\n",
        "print(\"Gemini PDF:\", gemini_pdf)\n",
        "print(\"OpenAI PDF:\", openai_pdf)\n",
        "print(\"AnyScale PDF:\", anyscale_pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNglfN9RG4U4"
      },
      "source": [
        "21. OCR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jy-qQX5cG4U4"
      },
      "outputs": [],
      "source": [
        "# Using all model\n",
        "gemini_image = gemini_model.text_ocr(\"image.png\", \"what logo is this?\")\n",
        "# openai_pdf = openai_model.text_ocr(\"image.png\", \"what is this image?\")\n",
        "\n",
        "print(\"Gemini OCR:\", gemini_image)\n",
        "# print(\"OpenAI OCR:\", openai_pdf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv-ai_competition_work",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}